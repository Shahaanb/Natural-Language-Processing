{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f191ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>...</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697200650592256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199560069120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199312482304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697197118861312</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697196967903232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               candidate  candidate_confidence relevant_yn  \\\n",
       "0   1  No candidate mentioned                   1.0         yes   \n",
       "1   2            Scott Walker                   1.0         yes   \n",
       "2   3  No candidate mentioned                   1.0         yes   \n",
       "3   4  No candidate mentioned                   1.0         yes   \n",
       "4   5            Donald Trump                   1.0         yes   \n",
       "\n",
       "   relevant_yn_confidence sentiment  sentiment_confidence     subject_matter  \\\n",
       "0                     1.0   Neutral                0.6578  None of the above   \n",
       "1                     1.0  Positive                0.6333  None of the above   \n",
       "2                     1.0   Neutral                0.6629  None of the above   \n",
       "3                     1.0  Positive                1.0000  None of the above   \n",
       "4                     1.0  Positive                0.7045  None of the above   \n",
       "\n",
       "   subject_matter_confidence candidate_gold  ... relevant_yn_gold  \\\n",
       "0                     1.0000            NaN  ...              NaN   \n",
       "1                     1.0000            NaN  ...              NaN   \n",
       "2                     0.6629            NaN  ...              NaN   \n",
       "3                     0.7039            NaN  ...              NaN   \n",
       "4                     1.0000            NaN  ...              NaN   \n",
       "\n",
       "  retweet_count  sentiment_gold subject_matter_gold  \\\n",
       "0             5             NaN                 NaN   \n",
       "1            26             NaN                 NaN   \n",
       "2            27             NaN                 NaN   \n",
       "3           138             NaN                 NaN   \n",
       "4           156             NaN                 NaN   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...         NaN   \n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...         NaN   \n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...         NaN   \n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...         NaN   \n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...         NaN   \n",
       "\n",
       "               tweet_created            tweet_id  tweet_location  \\\n",
       "0  2015-08-07 09:54:46 -0700  629697200650592256             NaN   \n",
       "1  2015-08-07 09:54:46 -0700  629697199560069120             NaN   \n",
       "2  2015-08-07 09:54:46 -0700  629697199312482304             NaN   \n",
       "3  2015-08-07 09:54:45 -0700  629697197118861312           Texas   \n",
       "4  2015-08-07 09:54:45 -0700  629697196967903232             NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0                       Quito  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3  Central Time (US & Canada)  \n",
       "4                     Arizona  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load local sentiment dataset\n",
    "csv = 'sentiment.csv'\n",
    "df_sentiment = pd.read_csv(csv)\n",
    "\n",
    "df_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5431bf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13871 entries, 0 to 13870\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   id                         13871 non-null  int64  \n",
      " 1   candidate                  13775 non-null  object \n",
      " 2   candidate_confidence       13871 non-null  float64\n",
      " 3   relevant_yn                13871 non-null  object \n",
      " 4   relevant_yn_confidence     13871 non-null  float64\n",
      " 5   sentiment                  13871 non-null  object \n",
      " 6   sentiment_confidence       13871 non-null  float64\n",
      " 7   subject_matter             13545 non-null  object \n",
      " 8   subject_matter_confidence  13871 non-null  float64\n",
      " 9   candidate_gold             28 non-null     object \n",
      " 10  name                       13871 non-null  object \n",
      " 11  relevant_yn_gold           32 non-null     object \n",
      " 12  retweet_count              13871 non-null  int64  \n",
      " 13  sentiment_gold             15 non-null     object \n",
      " 14  subject_matter_gold        18 non-null     object \n",
      " 15  text                       13871 non-null  object \n",
      " 16  tweet_coord                21 non-null     object \n",
      " 17  tweet_created              13871 non-null  object \n",
      " 18  tweet_id                   13871 non-null  int64  \n",
      " 19  tweet_location             9959 non-null   object \n",
      " 20  user_timezone              9468 non-null   object \n",
      "dtypes: float64(4), int64(3), object(14)\n",
      "memory usage: 2.2+ MB\n",
      "None\n",
      "                 id  candidate_confidence  relevant_yn_confidence  \\\n",
      "count  13871.000000          13871.000000            13871.000000   \n",
      "mean    6936.000000              0.855689                0.927304   \n",
      "std     4004.357127              0.241388                0.141696   \n",
      "min        1.000000              0.222200                0.333300   \n",
      "25%     3468.500000              0.674200                1.000000   \n",
      "50%     6936.000000              1.000000                1.000000   \n",
      "75%    10403.500000              1.000000                1.000000   \n",
      "max    13871.000000              1.000000                1.000000   \n",
      "\n",
      "       sentiment_confidence  subject_matter_confidence  retweet_count  \\\n",
      "count          13871.000000               13871.000000   13871.000000   \n",
      "mean               0.756936                   0.782801      45.803331   \n",
      "std                0.217682                   0.258215     153.981724   \n",
      "min                0.186000                   0.222200       0.000000   \n",
      "25%                0.651700                   0.641300       0.000000   \n",
      "50%                0.681300                   1.000000       2.000000   \n",
      "75%                1.000000                   1.000000      44.000000   \n",
      "max                1.000000                   1.000000    4965.000000   \n",
      "\n",
      "           tweet_id  \n",
      "count  1.387100e+04  \n",
      "mean   6.296058e+17  \n",
      "std    9.611863e+13  \n",
      "min    6.294531e+17  \n",
      "25%    6.294861e+17  \n",
      "50%    6.296726e+17  \n",
      "75%    6.296882e+17  \n",
      "max    6.297017e+17  \n",
      "sentiment\n",
      "Negative    8493\n",
      "Neutral     3142\n",
      "Positive    2236\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspect sentiment dataset\n",
    "print(df_sentiment.info())\n",
    "print(df_sentiment.describe())\n",
    "print(df_sentiment['sentiment'].value_counts())\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # basic cleaning: lowercase, remove punctuation, collapse spaces\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", str(text))\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to sentiment dataset (assumes columns 'text' and 'sentiment')\n",
    "df_sentiment['cleaned_text'] = df_sentiment['text'].apply(preprocess_text)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df_sentiment['cleaned_text'])\n",
    "y = df_sentiment['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d438ffb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.85      0.79      1722\n",
      "     Neutral       0.48      0.35      0.41       612\n",
      "    Positive       0.54      0.40      0.46       441\n",
      "\n",
      "    accuracy                           0.67      2775\n",
      "   macro avg       0.58      0.54      0.55      2775\n",
      "weighted avg       0.65      0.67      0.65      2775\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fece0940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>Carla K. Johnson, AP</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffpost.com/entry/american-airlin...</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>Mary Papenfuss</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffpost.com/entry/amy-cooper-lose...</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>Nina Golgowski</td>\n",
       "      <td>2022-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
       "1  https://www.huffpost.com/entry/american-airlin...   \n",
       "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
       "3  https://www.huffpost.com/entry/funniest-parent...   \n",
       "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
       "\n",
       "                                            headline   category  \\\n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
       "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
       "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
       "\n",
       "                                   short_description               authors  \\\n",
       "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
       "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
       "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
       "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
       "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
       "\n",
       "        date  \n",
       "0 2022-09-23  \n",
       "1 2022-09-23  \n",
       "2 2022-09-23  \n",
       "3 2022-09-23  \n",
       "4 2022-09-22  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load local news category dataset (JSON lines)\n",
    "news_file = 'News_Category_Dataset_v3.json'\n",
    "df_news = pd.read_json(news_file, lines=True)\n",
    "\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "684f24f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare news dataset for classification (use a fresh vectorizer)\n",
    "df_news['cleaned_text'] = df_news['headline'].apply(preprocess_text)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer_news = CountVectorizer()\n",
    "X = vectorizer_news.fit_transform(df_news['cleaned_text'])\n",
    "y = df_news['category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(X_train, y_train)\n",
    "y_pred_nb = model_nb.predict(X_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_lr = LogisticRegression(max_iter=1000)\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred_lr = model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f41a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.56      0.02      0.03       293\n",
      "ARTS & CULTURE       0.25      0.00      0.01       275\n",
      "  BLACK VOICES       0.61      0.13      0.22       889\n",
      "      BUSINESS       0.59      0.24      0.34      1216\n",
      "       COLLEGE       0.50      0.00      0.01       202\n",
      "        COMEDY       0.67      0.21      0.31      1022\n",
      "         CRIME       0.54      0.48      0.51       713\n",
      "CULTURE & ARTS       0.93      0.06      0.12       202\n",
      "       DIVORCE       0.92      0.36      0.52       664\n",
      "     EDUCATION       0.00      0.00      0.00       209\n",
      " ENTERTAINMENT       0.44      0.81      0.57      3419\n",
      "   ENVIRONMENT       1.00      0.02      0.04       313\n",
      "         FIFTY       0.00      0.00      0.00       263\n",
      "  FOOD & DRINK       0.66      0.60      0.63      1270\n",
      "     GOOD NEWS       0.44      0.01      0.03       270\n",
      "         GREEN       0.41      0.05      0.08       532\n",
      "HEALTHY LIVING       0.40      0.04      0.07      1302\n",
      " HOME & LIVING       0.83      0.51      0.63       879\n",
      "        IMPACT       0.40      0.03      0.06       673\n",
      " LATINO VOICES       0.50      0.00      0.01       238\n",
      "         MEDIA       0.78      0.10      0.18       607\n",
      "         MONEY       0.78      0.04      0.08       355\n",
      "     PARENTING       0.44      0.51      0.47      1768\n",
      "       PARENTS       0.60      0.04      0.07       795\n",
      "      POLITICS       0.47      0.94      0.63      7155\n",
      "  QUEER VOICES       0.71      0.41      0.52      1262\n",
      "      RELIGION       0.76      0.07      0.13       530\n",
      "       SCIENCE       0.83      0.22      0.35       424\n",
      "        SPORTS       0.74      0.47      0.58      1014\n",
      "         STYLE       0.67      0.00      0.01       464\n",
      "STYLE & BEAUTY       0.63      0.77      0.70      1975\n",
      "         TASTE       0.33      0.00      0.00       427\n",
      "          TECH       0.84      0.11      0.19       398\n",
      " THE WORLDPOST       0.49      0.28      0.36       741\n",
      "        TRAVEL       0.59      0.71      0.64      2021\n",
      "     U.S. NEWS       0.00      0.00      0.00       269\n",
      "      WEDDINGS       0.86      0.40      0.54       709\n",
      "    WEIRD NEWS       0.57      0.09      0.16       550\n",
      "      WELLNESS       0.39      0.82      0.53      3672\n",
      "         WOMEN       0.76      0.06      0.11       727\n",
      "    WORLD NEWS       0.51      0.16      0.24       665\n",
      "     WORLDPOST       0.73      0.03      0.06       534\n",
      "\n",
      "      accuracy                           0.50     41906\n",
      "     macro avg       0.57      0.23      0.26     41906\n",
      "  weighted avg       0.55      0.50      0.43     41906\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.39      0.21      0.27       293\n",
      "ARTS & CULTURE       0.32      0.16      0.22       275\n",
      "  BLACK VOICES       0.50      0.37      0.43       889\n",
      "      BUSINESS       0.47      0.45      0.46      1216\n",
      "       COLLEGE       0.44      0.36      0.40       202\n",
      "        COMEDY       0.50      0.42      0.46      1022\n",
      "         CRIME       0.52      0.52      0.52       713\n",
      "CULTURE & ARTS       0.54      0.30      0.39       202\n",
      "       DIVORCE       0.81      0.68      0.74       664\n",
      "     EDUCATION       0.45      0.24      0.32       209\n",
      " ENTERTAINMENT       0.62      0.73      0.67      3419\n",
      "   ENVIRONMENT       0.51      0.25      0.34       313\n",
      "         FIFTY       0.43      0.19      0.26       263\n",
      "  FOOD & DRINK       0.65      0.70      0.67      1270\n",
      "     GOOD NEWS       0.39      0.21      0.27       270\n",
      "         GREEN       0.34      0.27      0.30       532\n",
      "HEALTHY LIVING       0.29      0.21      0.24      1302\n",
      " HOME & LIVING       0.74      0.69      0.72       879\n",
      "        IMPACT       0.33      0.24      0.28       673\n",
      " LATINO VOICES       0.65      0.30      0.41       238\n",
      "         MEDIA       0.62      0.43      0.51       607\n",
      "         MONEY       0.50      0.34      0.40       355\n",
      "     PARENTING       0.49      0.58      0.53      1768\n",
      "       PARENTS       0.39      0.27      0.32       795\n",
      "      POLITICS       0.69      0.82      0.75      7155\n",
      "  QUEER VOICES       0.72      0.65      0.68      1262\n",
      "      RELIGION       0.60      0.46      0.53       530\n",
      "       SCIENCE       0.58      0.47      0.52       424\n",
      "        SPORTS       0.68      0.63      0.65      1014\n",
      "         STYLE       0.46      0.29      0.36       464\n",
      "STYLE & BEAUTY       0.73      0.77      0.75      1975\n",
      "         TASTE       0.42      0.20      0.28       427\n",
      "          TECH       0.51      0.44      0.47       398\n",
      " THE WORLDPOST       0.44      0.38      0.41       741\n",
      "        TRAVEL       0.68      0.76      0.72      2021\n",
      "     U.S. NEWS       0.27      0.12      0.17       269\n",
      "      WEDDINGS       0.77      0.75      0.76       709\n",
      "    WEIRD NEWS       0.40      0.30      0.34       550\n",
      "      WELLNESS       0.48      0.75      0.59      3672\n",
      "         WOMEN       0.43      0.34      0.38       727\n",
      "    WORLD NEWS       0.41      0.32      0.36       665\n",
      "     WORLDPOST       0.42      0.26      0.32       534\n",
      "\n",
      "      accuracy                           0.58     41906\n",
      "     macro avg       0.51      0.42      0.46     41906\n",
      "  weighted avg       0.57      0.58      0.57     41906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
